{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of my project, apart from data analysis, was to take the top results from the Kaggle competition and analyze what made them do well.\n",
    "\n",
    "This is both to understand the systems used to solve the competition, and to learn the ideas necessary to boost other possible solutions.\n",
    "\n",
    "All of the credited full documentations of each solution are in the ../Top folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Place Solution\n",
    "\n",
    "The first solution used a combination of CatBoost alongside other methods in order to achieve the highest score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their first realization had to do with the cross validation metrics. They mention the importance of having a good cross validation scheme, arguing it's one of the most important points in winning one of these competitions. \n",
    "\n",
    "People doing the competition were able to see a sliver of the testing set as a \"public accuracy\" before the deadline was over, but, other than that, all that was available were metrics createdd with the training data.\n",
    "\n",
    "This solution, instead of using the public accuracy, used exclusively their own cross validation scores in order to find which models worked and which ones didn't. \n",
    "\n",
    "They used a five-fold validation set with two repeats, creating a total of 10 different splits to average between."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models that were chosen to analyze were LightGBM, XGBoost, CatBoost, and a standard neural network.\n",
    "\n",
    "Each of these had fine tuned parameters using Optuna, and their performance on the cross-validation score was analyzed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM\n",
    "\n",
    "LightGBM, which was briefly mentioned during the class lectures, is a gradient-boosting machine learning framework. \n",
    "\n",
    "It uses decision trees, like many other boosting algorithms, but it has some minor technical differences that provide it with its own niche.\n",
    "\n",
    "Instead of growing a tree row by row, LightGBM has trees that grow \"leaf-wise\". It picks the leaf with the lowest loss, and grows in that direction specifically. This, alongside with using a different decision-tree learning algorithm, allow LightGMB to be much more efficient, both time and memory wise, than other frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "\n",
    "XGBoost is another common gradient boosting framework, which started as a sole research project, and gained traction and popularity as it kept being used in winning results for machine learning competitions.\n",
    "\n",
    "Similar to LightGBM, it creates a large forest of decision trees to boost their accuracy. While this creates much better results, it does sacrifice the simple readability of a decision tree.\n",
    "\n",
    "XGBoost started with a basic gradient boosting algorithm, and took its own small changes on known formats in order to make it more accurate.\n",
    "\n",
    "XGBoost serves as a base for other commonly used boosting methods, such as LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost\n",
    "\n",
    "CatBoost, again, is a common gradient boosting framework. The main difference in CatBoost is it tries to account for categorical features more.\n",
    "\n",
    "That makes it very useful for this dataset, which contains a large amount of categorical columns.\n",
    "\n",
    "CatBoost, within recent years, is one of the most popular and fastest growing frameworks to be used.\n",
    "\n",
    "This gained popularity comes with native categorical fetaure handling, alongside other bonuses. Categorical feature handling is important since normally, categorical columns would have to be treated as numeric. This would evidently decrease the accuracy, since numeric and categorical columns should be handled in different ways for maximal results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optuna\n",
    "\n",
    "Optuna is a popular open-source hyperparameter optimization framework.\n",
    "\n",
    "It's particularly designed for machine learning,and it finds the optimal hyperparameters for a given model and given data.\n",
    "\n",
    "This helps find good starting points for stochastic search or lets you skip stochastic search entirely, depending on your purpose and time constraints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the first run of tests, the highest performaing model was CatBoost. \n",
    "\n",
    "This is because the second realization in this top solution, which was to treat some of the numeric values as categorical. Multipe of features have little enough variety where they can be deemed as separate ideas, and that allows more accurate predictions.\n",
    "\n",
    "Since CatBoost works closely with categorical data, this allows CatBoost to create the most accurate score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of CatBoost's startlingly high performance, they took a second CatBoost model and trained it using each separate set of completed conditions from the first test.\n",
    "\n",
    "The LightGBM, XGBoost, CatBoost, and neural network results were thrown through a second iteration of CatBoost, and this allowed for a higher final result.\n",
    "\n",
    "The final best model was found through using CatBoost on the previous CatBoost results, resulting in a final test accuracy of 96.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Place Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second solution's secret to success was relatively simple, creating a custom ensemble of various created models, and then using hill climbing to optimize them.\n",
    "\n",
    "Instead of using just solitary boosting algorithms, like shown in the previous solution, this method allows a higher level of personal control, and a more hands on approach to solving the problem.\n",
    "\n",
    "A heavy understanding of each individual model isn't required to understand why this method worked, but the models used were LightGBM, Dart, XGBoost, ExtraTrees, Random Forest, CatBoost, KNN, MLP, and Goss methods. Most of these are things mentioned earlier or things discussed in class.\n",
    "\n",
    "Each individual model was run through Optuna or a similar stochastic searching process in order to gauge the most optimal hyperparameters before the hill climbing process started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hill Climbing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hill climbing is a unique stochastic searching algorithm that finds the best subset of an inputted set of models, sourced from [here](https://github.com/Matt-OP/hillclimbers)\n",
    "\n",
    "It will start with one model, experiment with changing parameters and adding new models, only making changes that increase accuracy.\n",
    "\n",
    "Through this repeated process, it will eventually converge on a local / global  minimum / maximum, similar to gradient descent or any similar algorithm.\n",
    "\n",
    "This is helpful because it allows you to really experiment with anything you would want to add to your ensemble. If you add a model and it doesn't get used, nothing bad happens, the model just isn't included. This allows you to keep adding options to your ensemble until you get a score you're happy with or run out of ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tihs solution, hill climbing is used across all of the aforementioned models. Every single step of the hill climbing alorithm slightly increased the ensemble's accuracy, until a peak was reached.\n",
    "\n",
    "By using a combination of CatBoost, XGBoost, Random Forest, Darrt, and ExtraTrees, the highest accuracy score on the testing set was reached. While it wasn't shown explicitly whether this was tested aginst the cross validation sets, the public portion of the testing set, or the entire testing set, we can see this model did perform the best of any other step on the process.\n",
    "\n",
    "Assumedly these processes were run multiple times, but the best one (which found the spot closest to a global extrema) was te one saved and submitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Place Solution\n",
    "\n",
    "While the third place solution didn't have a public notebook available, the fourth solution, which we'll analyze in its place, does."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
